{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的主要优势就在于数据形式非常容易理解，而这也是kNN最主要的缺点之一；\n",
    "\n",
    "决策树：\n",
    "\t1. 根据某一特征进行数据集划分\n",
    "\t2. 判断划分后各个子数据集中的数据是否均为同一类型的\n",
    "\t\t是：返回节点类型\n",
    "\t\t否：使用当前子数据集创建新节点，返回步骤1处理新节点\n",
    "\t关键：\n",
    "\t\t1. 何时停止划分数据集，也是递归结束的条件ID3（ID3处理如何划分数据集，以及何时停止）；\n",
    "\t\t2. 如何决定使用那个特征划分数据集，根据香农熵，选择最大信息增益的特征划分；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树的构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分数据集的大原则是:将无序的数据变得更加有序，方法有很多也各有优劣，其中一种方法是使用信息论度量信息；\n",
    "\n",
    "划分数据集前后信息的变化称之为信息增益，知道如何计算信息增益，我们就可以获取到使得信息增益最大的那个特征作为划分数据集的特征，此处需要使用香农熵来计算信息增益；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算香农熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    熵定义为信息的期望值，在明晰这个概念之前，我们必须知道信息的定义，如果待分类的事务可能划分在多个分类之中，则符号 x_i 的信息定义为：\n",
    "\tl(x_i) = -log_2 p(x_i)\n",
    "\t其中p(x_i)是选择该分类的概率；\n",
    "\t为了计算熵，我们需要计算所有类别所有可能值包含的信息期望值，通过下面的公式得到：\n",
    "\t-sum(p(x_i)*log_2 p(x_i)) i={1,2,3.....n} n为目标变量总类别数\n",
    "\t从公式可以看出含义是：各个类别自身的概率乘以自己的信息量，最后求和得到熵；\n",
    "    \n",
    "    可以说香农熵就是用于度量数据分类的无序程度，因此分类越多，熵会越大；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 3, 'B': 2}\n",
      "0.970950594455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcShannonEntropy(dataSet):\n",
    "\t\t\"\"\"\n",
    "\t\t统计类别信息\n",
    "\t\t1. 获取到所有分类，创建字典\n",
    "\t\t2. 为每个字典设置其对应分类在数据集中数量\n",
    "\t\t3. 通过数量和总数计算熵\n",
    "\t\t\"\"\"\n",
    "\t\tclasses = {}\n",
    "\t\tfor d in dataSet:\n",
    "\t\t\tclasses[d[-1]] = classes.get(d[-1],0)+1 # 如果没有则设置-1+1，即0，如果有则加1\n",
    "\t\tprint classes\n",
    "\t\tcount = 1.*len(dataSet)\n",
    "\t\tentropy = -sum([classes[k]/count*math.log(classes[k]/count,2) for k in classes.keys()])\n",
    "\t\tprint entropy\n",
    "\t\treturn entropy\n",
    "\n",
    "calcShannonEntropy(np.array([[1,1,'A'],[1,2,'B'],[2,1,'A'],[2,3,'A'],[3,2,'B']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 4, 'B': 2, 'E': 2, 'D': 1, 'F': 1}\n",
      "2.12192809489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1219280948873624"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcShannonEntropy(np.array([[1,1,'A'],[1,2,'B'],[2,1,'A'],[2,3,'A'],[3,2,'B'],[3,2,'A'],[3,2,'F'],[3,2,'E'],[3,2,'E'],[3,2,'D']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵越高,则混合的数据也越多；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value): # 改善一下，原代码是根据value，每次返回当前数据集中对应特征值为value的数据子集，改为返回所有value的数据子集，以字典形式返回\n",
    "\t\"\"\"\n",
    "\t将数据集根据某个特征axis分割为每个特征值对应的数据子集，以dict形式返回\n",
    "\t\"\"\"\n",
    "\tdataDict = {}\n",
    "\tfor d in dataSet:\n",
    "\t\tv = dataDict.get(d[axis],[])\n",
    "\t\tv.append(np.append(d[:axis],d[axis+1:]))\n",
    "\t\tdataDict[d[axis]] = v\n",
    "\treturn dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': [array(['1', 'A'],\n",
       "        dtype='|S21'), array(['2', 'B'],\n",
       "        dtype='|S21')], '2': [array(['1', 'A'],\n",
       "        dtype='|S21'), array(['3', 'A'],\n",
       "        dtype='|S21')], '3': [array(['2', 'B'],\n",
       "        dtype='|S21')]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDataSet(np.array([[1,1,'A'],[1,2,'B'],[2,1,'A'],[2,3,'A'],[3,2,'B']]), 0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择最佳特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeature2Split(dataSet):\n",
    "\t\"\"\"\n",
    "\t选择将数据集划分后总熵最小的那个特征以及对应的熵值，数据子集的dict形式返回\n",
    "\t\"\"\"\n",
    "\taxiss = len(dataSet[0])-1 # 去掉最后一个目标变量，否则肯定是该变量最符合要求，按照目标变量划分数据再用目标变量来评估xD\n",
    "\tminEntropy = 99999999\n",
    "\tminAxis = -1\n",
    "\tminDataDict = None\n",
    "\tfor axis in range(axiss):\n",
    "\t\tdataDict = splitDataSet(dataSet, axis, None)\n",
    "\t\tsumEntropy = sum([calcShannonEntropy(dataDict[k]) for k in dataDict.keys()])\n",
    "\t\tprint dataDict\n",
    "\t\tprint sumEntropy\n",
    "\t\tif sumEntropy < minEntropy:\n",
    "\t\t\tminEntropy = sumEntropy\n",
    "\t\t\tminAxis = axis\n",
    "\t\t\tminDataDict = dataDict\n",
    "\tprint 'min entropy:'+str(minEntropy)\n",
    "\tprint 'min axis:'+str(minAxis)\n",
    "\tprint 'min data dict:'+str(minDataDict)\n",
    "\treturn minEntropy, minAxis, minDataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 1, 'B': 1}\n",
      "1.0\n",
      "{'B': 1}\n",
      "-0.0\n",
      "{'A': 2}\n",
      "-0.0\n",
      "{'1': [array(['1', 'A'],\n",
      "      dtype='|S21'), array(['2', 'B'],\n",
      "      dtype='|S21')], '3': [array(['2', 'B'],\n",
      "      dtype='|S21')], '2': [array(['1', 'A'],\n",
      "      dtype='|S21'), array(['3', 'A'],\n",
      "      dtype='|S21')]}\n",
      "1.0\n",
      "{'A': 2}\n",
      "-0.0\n",
      "{'A': 1}\n",
      "-0.0\n",
      "{'B': 2}\n",
      "-0.0\n",
      "{'1': [array(['1', 'A'],\n",
      "      dtype='|S21'), array(['2', 'A'],\n",
      "      dtype='|S21')], '3': [array(['2', 'A'],\n",
      "      dtype='|S21')], '2': [array(['1', 'B'],\n",
      "      dtype='|S21'), array(['3', 'B'],\n",
      "      dtype='|S21')]}\n",
      "0.0\n",
      "min entropy:0.0\n",
      "min axis:1\n",
      "min data dict:{'1': [array(['1', 'A'],\n",
      "      dtype='|S21'), array(['2', 'A'],\n",
      "      dtype='|S21')], '3': [array(['2', 'A'],\n",
      "      dtype='|S21')], '2': [array(['1', 'B'],\n",
      "      dtype='|S21'), array(['3', 'B'],\n",
      "      dtype='|S21')]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1, {'1': [array(['1', 'A'],\n",
       "         dtype='|S21'), array(['2', 'A'],\n",
       "         dtype='|S21')], '2': [array(['1', 'B'],\n",
       "         dtype='|S21'), array(['3', 'B'],\n",
       "         dtype='|S21')], '3': [array(['2', 'A'],\n",
       "         dtype='|S21')]})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeature2Split(np.array([[1,1,'A'],[1,2,'B'],[2,1,'A'],[2,3,'A'],[3,2,'B']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 递归构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
