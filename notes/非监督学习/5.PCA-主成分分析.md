# 主成分分析

## 概述
主成分分析是将数据从旧的坐标系移动至新的坐标系；

以2D为例
1. 新坐标系的原点：通常取数据集的中点；
2. 新坐标系的x轴为数据主要变化的方向上；
3. y轴则选择与之正交的数据次要变化的方向上；

## 作用
将多个特征进行组合，通常用于降维，且这种方式的降维最大程度保留了特征的作用，这个生成的新特征称之为*主成分*；

想象一下一个2D空间的数据集，大体呈一条斜向上的带状，那么对这个数据集做主成分分析：
1. 得到新坐标系；
2. 其中x轴是主要变化的方向；
3. 将数据点映射到x轴；
4. 取消y轴；
5. 此时数据集变为一维，且最大程度保留了旧坐标系中二维数据的成分；

## 主成分方向
由数据中的最大方差决定，也就是数据点间最长的线；

## 了解数据
PCA会让你更加了解特征，如果我们不确定如何进行特征的组合，那么可以将全部特征统统丢进PCA中，它会自动进行特征组合，
生成各种主成分，而我们也不再关心，这些主成分到底是哪几个特征的组合生成的了；

## 最大主成分的数量
等于训练数据个数和特征个数中小的那个，一般都是特征个数啦；

## 使用
更多用在数据预处理后吧，在人工的去了解数据后手工进行主成分提取，或者自动进行PCA来实现降维等功能；

## sklearn中的PCA
from sklearn.decomposition import PCA
1. 指定主成分个数-n_components
2. fit数据得到pca对象
3. 使用pca的transform来转换数据到新坐标系上

## 什么时候使用PCA
1. 确定是否有隐含特征，也就是确定主成分的占比；
2. 降维；
    1. 数据可视化，例如将四维数据降低到二维上去可视化它；
    2. 去除噪音，假设不确定是否有噪音时，可以进行主成分分析，如果有占比很小的特征，那么可能就属于噪音；
    3. 在其他分类、回归算法前使用PCA，好处除了上述2以外，还可以避免维度灾难等；

举例人脸识别中PCA的应用：
1. 人脸识别的数据维度很高；
2. 确实有很多隐含特征，比如两只眼睛、一个嘴巴等等，而这些特征是不存在于原始特征中的；

对于人脸识别中的PCA应用，最终得到的主成分并不像我们描述的两个眼睛、一个鼻子、嘴巴大小这么的直观，相反，它得到的是
一种能够可视的称之为特征脸的新特征（当然了，可视后也看不出这个特征到底想说什么），但是要直到虽然对人来说看不懂，但是
这是PCA算法自己决定的要用的主成分，也就是说对PCA来说，这些新特征对于它后续进行预测等是非常有用的；

## 主成分选择：个数还是百分比
如果明确知道有几个主成分需要保留，那么就选择个数，否则可以选择百分比，例如保留原特征个数的20%；

通常：具体主成分选择几个一般都是有一个尝试的过程的，从低到高慢慢尝试，直到主成分个数的增长无法带来更高的f1-score或准确率等，甚至
可能还会降低，那么此时就选择之前的个数，建议从10%开始，每次1%的个数递增或者递减；

## 主成分个数作为参数
是PCA中最重要的参数，有点类似树的层数，太少容易丢失特征，导致不足以描述原始数据特点，太多容易过拟合；
