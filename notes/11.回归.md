# 回归

## 连续输出
跟上一章不同的是，本章会看到一些连续的输出，比如上一章中车辆根据地形、颠簸、是否限速的这三个特征的输入最终得到的
输出是slow或者fast，这就是一个离散的输出结果，而比如根据身高这个特征的输入，输出体重，那么此时的体重就是一个连续
的输出；

## 连续输出和离散输出
连续输出：
    1. 按照出生后每秒进行编码后的年龄；
    2. 天气：单位时间内投射到地面上的阳光的量；
    3. 收入水平；
离散输出：
    1. 天气：晴天、雨天；
    2. 身份编号：虽然也可以是顺序的数值，但是这个顺序本身是没有实际意义的，因此是离散的；
    3. 电话号码；

tips：
* tip 1：很多时候，离散输出在某些情况下都可以用连续输出来表示；
* tip 2：辨别连续数值是连续还是离散，主要关注数值的连续是否有实际意义，比如体重，数值越大，体重越大，而对于工号来说，这个顺序是没有实际意义的；

对应：
* 离散输出：对应分类问题；
* 连续输出：对应回归问题；

## 斜率和截距
也就是斜截式，所谓监督学习的拟合直线，就是求这个方程式的斜率和截距；

通过sklearn提取信息：
* reg.coef\_提取斜率；
* reg.intercept\_提取截距信息；
* reg.score计算的是r^2；

score区别：在分类问题中的score返回是就是分类结果与真实结果的准确率，比如对100个测试数据进行分类，其中有90个是正确的，那么score就是0.9，而对于回归
问题来说，该值代表的并不是预测的准确率（如果是的话估计这个值无线接近0），因为输出是连续的，很难预测出一模一样的值，因此此时的这个值就是r^2来表示，
结果的数值意义与分类一致，越大越好，最大是1.0；

## 如何评估线性回归模型
误差：
* 回归：实际的值与预测值的差；
* 分类：对错；

一般有两种：
* 误差平方和；
* r^2；

## 最小化误差平方和的算法 -- 即找到合适的斜率和截距
* 普通最小二乘法 -- sklearn的线性模型使用该算法最小化误差平方和；
* 梯度下降法；

## 为何使用平方和，而不是绝对值和
想象以下情况：

样本数据有以下四个：(1,1),(2,2),(3,1),(4,2)

如果是按照绝对值和来进行最小化的话有一个问题：会存在多条拟合直线都有同一个最小化的绝对值误差和，因为存在直线两侧有两个点时，不管直线靠近哪个点，计算
出的两个误差的绝对值的和都是一样的；

如果是使用平方和的话不存在这个问题，比如直线在中间时，距离分别是2和-2，那么平方和就是8，而过直线靠近某一个样本，距离变为1和-3，那么平方和就是10，明显
变大了，因此使用平方和是有唯一解的；

## 使用最小化平方和作为评估模型标准的问题
这个值本身由于是求和，且不存在负数，因此可以说样本量越多，该值越大，因此无法在不一致的样本量上进行测试的模型之间使用该值比较性能，此时简单的话其实应该
可以使用平均平方和来比较哈；

## r^2
r^2回答的是以下问题：
> 有多少输出的改变可以用输入的改变来解释；

对比误差平方和的优点：
* 始终在0~1之间，越大表示拟合越好；
* 与训练样本量无关；

# 分类与回归对比
分类：
    * 输出类型：离散；
    * 算法真正找的是什么：决策边界；
    * 性能评估指标：准确率；

回归：
    * 输出类型：连续；
    * 算法真正找的是什么：最优拟合线；
    * 性能评估指标：误差平方和、r^2；

## 多元回归
输出不止一个变量，比如对应年龄--净资产的例子中，输入我们改为年龄、IQ、学历，那么对应的方程式是怎样的呢？
> 其实就是在原来的方程式中增加x的数量，y=m\*x1+n\*x2.....+z
