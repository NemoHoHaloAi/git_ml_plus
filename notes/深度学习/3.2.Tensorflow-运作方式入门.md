# TensorFlow运作方式

## 输入与占位符-input and placeholder
输入是对于op来说的，也就是说对于某个op来说是输入，当然它本身也可能是某个op的输出，或者是一个constant、variable等，
而占位符可以理解为它的目的也是输入，但是这个输入的不同在于，它是在run的过程中确认具体数据的，因此需要先定义这么
一个东西用来在流中占据一个位置，然后在run过程中持续对它进行赋值操作；

## 构建图表-build the graph
1. inference - 尽可能的构建好图表，满足神经网络向前反馈并做出预测的要求；
2. loss - 向图表中加入计算损失的op；
3. training - 向图表中加入梯度的部分对参数进行训练；

### 推理-inference
推理过程就是构建主要Tensor流的过程，本质就是在搭建神经网络的整个正向运行框架，一个op接一个op的流程，构建好的框架就是
等会要训练的模型，例如在MNIST中的构建过程如下：1.定义格式化输入，2.第一层卷积，3.第二层卷积，4.池化，5.Dropout；这就
是一个典型的多层卷积神经网络模型；

### 定义损失函数-loss
向图表中增加定义损失的op，最终优化是要通过某个op来判断当前的效果的，然后根据这个op的结果进行持续不断地优化；

### 训练-train
向图表中增加训练op，训练op通过之前指定的loss op，以及指定的优化方式（某种梯度下降）、步长等参数进行持续优化；

## 训练模型-Train the model
一旦图表构建完毕（包含了模型主流程、loss、训练），那么就可以通过循环迭代式的对模型进行训练和评估；

### 图表-graph
因为TensorFlow中所有事务都依赖于图表所存在，因此要指定一个图表，但是一般都使用默认图表即可，多图表的复杂应用也是存在的；

### 会话-session
在图表构建完毕后，就要进入执行阶段，该阶段依赖于session的存在，因此通常都使用**with tf.Session() as sess:**开始该阶段，该
阶段开始通常首先会通过**tf.initialize_all_variables()**初始化变量们，**sess.run()i**方法将会运行图表中与作为**参数传入**的**操作**相对应
的完整**子集**，也就是说如果op3调用了op2，op2调用了op1，那么直接run(op3)时，会依次执行op1,op2,op3；

### 训练循环-train loop
最简单的循环训练如下：

		for step in xrange(max_steps):
			sess.run(train_op)

当然，我们的MNIST例子更复杂一点，使用了占位符来实现每次训练时提供不一样的数据切片；

### 向图表提供反馈-back to graph
每次循环开始时，我们都会得到一份不同的用于填充占位符的数据，将这些数据通过feed_dict参数传递给run方法，实现不同数据对训练过程的反馈；

### 检查状态-check state
如果模型在训练中出现偏差，loss Tensor的值可能会变成NaN，为了避免这种问题，我们可以将loss的输出记录下来，隔一段时间打印一下，通知用户
当前的训练状态；

### 状态可视化-state visualization
保存实时训练数据，事后可以通过TensorBoard将实时训练数据可视化进行分析等工作；

### 保存检查点-save checkpoint
可以理解为它是一个模型的现场文件，记录模型的当前情况（主要应该是参数吧），然后持久化到磁盘，后期可以再加载出来继续对模型进行训练和评估，而
不需要再从头开始训练：

		为了得到可以用来后续恢复模型以进一步训练或评估的检查点文件（checkpoint file），我们实例化一个tf.train.Saver。
	
		saver = tf.train.Saver()
	
		在训练循环中，将定期调用saver.save()方法，向训练文件夹中写入包含了当前所有可训练变量值得检查点文件。
	
		saver.save(sess, FLAGS.train_dir, global_step=step)
	
		这样，我们以后就可以使用saver.restore()方法，重载模型的参数，继续训练。
	
		saver.restore(sess, FLAGS.train_dir)

## 评估模型-model evaluation
每隔N个训练步骤，我们的代码会尝试使用训练数据集与测试数据集，对模型进行评估，分别使用训练数据集、验证数据集合测试数据集；

注意，更复杂的使用场景通常是，先隔绝data_sets.test测试数据集，只有在大量的超参数优化调整（hyperparameter tuning）之后才进行检查。
但是，由于MNIST问题比较简单，我们在这里一次性评估所有的数据。

### 构建评估图表-build evaluation graph
喵喵喵zzzz；

### 评估图表的输出-graph output evaluation
喵喵喵zzzz；
