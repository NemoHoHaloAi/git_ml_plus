# 博弈论

## 什么是博弈论
* 冲突的数学
* 单一智能体 -> 多智能体
* xxx
* xxx

## 简单例子 - 两个玩家、零和、确定的、完美信息博弈
比如下棋，你一步，我一步，将我每一步的选择都组合起来就是我的所有可选策略，你的也一样，比如：

    我：         [start]
                    |
                L       R
    你：        |       |
            L   M   R   R
            |   |   |   +2
            +7  +3  |
                    |
    我：        L       R
                -1      +4

    纯策略：
        对于我来说：总共有两个节点，分别对应第一步和第三步，每一步都只有l，r两种选择，因此所有策略为ll,lr,rl,rr
        对于你来说：同样有两个节点，但是都对应第二步（由我第一步的选择决定），第一步有l,m,r三个选择，第二步只有r一个选择因此所有策略为lr,mr,rr

    由此可绘制一个策略选择矩阵：
        你  lr  mr  rr
    我
    ll      +7  +3  -1
    lr      +7  +3  +4
    rl      +2  +2  +2
    rr      +2  +2  +2

    假设由我先选择策略，你后选的话，由于期望奖励最大，我会选择lr，也就是第二排，而你会选择mr，也就是第二列，因此得到最终值为+3
    假设由你先选择策略，我后选的话，你会选择mr，我会选择ll/lr，最终值依然是+3

    也就是说，对于一个双智能体，零和，完美信息博弈来说，结论是一致的；

## 最大最小值
你选对你来说最大的策略，我选对你来说最小的策略（反之这个对我来说就是最大的），称之为最大最小值；

## 理论
在2个玩家的零和确定性完美信息博弈中，最大最小值等于最小最大值，每个玩家总是存在一个最优的纯策略；

## 假设
博弈论的玩家在选择自己的策略时，总是假设其他玩家也在最大化自己的奖励，因此这也是需要考虑的，比如对于上述例子来说，对于玩家我，
似乎选择ll还是lr都是一样的结果，但是由于我们知道玩家你会试图最大化自己的奖励，因此我们选择lr，因为ll中最差的可能是-1，同样的
如果是你先做选择，虽然-1是最佳的，但是这一列有一个+4，因此你会选择mr作为自己的策略，这样我就最多只能得到+3，因此不管是谁先选，
结果都是一样的：我lr，你mr；

## 如果不确定呢 - 两个玩家、零和、不确定的、完美信息博弈
加入概率到博弈树中！！！！

唯一影响的只是对于奖励值的计算，比如0.5的可能得到+4，0.5的可能得到-2，那么对应的总体奖励就是0.5\*4+0.5\*-2=1

冯诺依曼提出的理论，最大最小值同样适用于不确定的情况；

## 迷你扑克 - 两个玩家、零和、不确定的、不完美信息博弈
同样还是我和你两个玩家，初始我会得到一张牌，可能为红，可能为黑，黑对我来说是奖励，红对我来说是惩罚，对你相反，得到哪张牌概率
都是0.5，得到牌之后我的可选动作为弃牌以及保留牌，如果我保留牌，那么你的可选动作为弃牌以及查看牌，下面是该问题的博弈树：

                    [发牌]
            |                   |
            0.5:红              0.5:黑
    我      |                   |
        |       |               |
        弃牌    保留            保留
        -20     |               |
    你      |       |       |       |
            弃牌    查看    弃牌    查看
            +10     -40     +10     +30

    对于我，所有策略为：弃牌、保留，对于你：弃牌、查看
    所谓**隐藏信息**的含义是对于你来说，我手中牌的颜色是不可见的，是隐藏的

    矩阵：
        你      弃牌                    查看
    我
    弃牌        0.5*-20+0.5*10=-5       0.5*-20+0.5*30=5
    保留        0.5*10+0.5*10=10        0.5*-40+0.5*30=-5

    此时我们发现如果是我先做决策，我会选择保留，而你会选择查看，如果是你先做决策，你会选择查看，而我会选择弃牌，因此在此种情况
    下，最大最小值的唯一理论是不成立的，原因就是由这个隐藏信息导致的，这也引出我们下一个内容：**混合策略**


## 混合策略 - 针对最大最小值理论不唯一
与纯策略唯一不同的是，在混合策略中，我们需要确定玩家选择每种策略的**概率**；

假设我保留牌的概率为p：

    当你总是弃牌时，奖励为：
        p*10-(1-p)*5=15p-5
    当你总是查看时，奖励为：
        p*(-5)+(1-p)*5=5-10p

    此时，根据我保留牌的概率不同，会得到针对你两种行为的两个奖励值，比如我总是保留牌，也就是说p为1，那么：
        你弃牌时，奖励为：10
        你查看时，奖励为：-5
    当我总是弃牌时：
        你弃牌时，奖励为：-5
        你查看时，奖励为：5
    可以看到，跟上述矩阵是一致的；

    可以根据p的值（作为横坐标）绘制两条直线表示随着p的变化，当你选择弃牌还是查看时的最终奖励的变化趋势，而这两条直线是有交点的；

    根据公式可知**交点**为：15p-5=5-10p，即p=.4，那么奖励就是1；

同样的，假设由你弃牌的概率为p来看待问题：

    当我总是弃牌时，奖励为：
        p*(-5)+(1-p)*(5)=5-10p
    当我总是保留时，奖励为：
        p*(10)+(1-p)*(-5)=15p-5
    我们发现还是这两个公式，只是顺序反过来了，那么所计算的交点依然是原来的p为.4，期望为1；

因此可以说，在混合策略下，我们再次实现了唯一；


## 告密者 - 两个玩家、非零和、不确定、非完美博弈
例子：有两个罪犯，他们都被警察逮捕，因为抢劫，现在摆在他们面前的有一个问题，是选择互相合作不供认，还是背叛对方，指正对方，
因此有四种情况，如果a选择忠诚，b选择忠诚，那么警察没有人证，但是由于发现了枪支，因此判每人一个月，也就睡奖励为-1，如果a选择
忠诚，但是b选择背叛，那么a将面临九个月的监禁，即奖励为-9，而b则立马出狱，即奖励为0，反之依然，而当二者都选择背叛时，由于认错
态度不错，那么a和b都被判六个月监禁，即奖励为-6，矩阵如下：

    罪犯b       忠诚        背叛
    罪犯a
    忠诚        -1,-1       -9,0    
    背叛        0,-9        -6,-6

    注意：此时整个矩阵已经不再是零和的了；

    可以看出，对于每个罪犯，可选策略都只有忠诚和背叛，而出于最大化自己的奖励而言，每个罪犯都应该选择背叛，那么也存在唯一；

    这称之为**囚徒困境**；

## Nash均衡
假设有N个玩家，每个玩家都可以选择多种策略，比如S1表示玩家1的所有可选策略，假设存在这样一个序列：

> s1\*,s2\*....sN\*

且当且仅当，给以任何一个玩家机会在**知道其他玩家的选择时**决定要不要去**改变**自己的策略，如果此时任何一个玩家都不会去改变，那么我们称
此时的所有玩家的策略序列处于Nash均衡状态；

Nash均衡适用于纯策略和混合策略，对于纯策略，就是玩家不会对自己**选择的策略**做出改变，对于混合策略，则是玩家不会对自己**混合策略的概率**
做出改变；

三个Nash均衡的理论：
1. 在n个玩家的纯策略中，如果淘汰（这个淘汰可能是反复删减完成的）掉所有经过严格提名的策略，只剩下一组策略，剩下的就是唯一的符合Nash均衡的策略；
2. 任何Nash均衡都将在反复删减的淘汰中存活下来；
3. 在有限的玩家数量、有限的玩家可选策略情况下，至少有一个Nash均衡可能涉及混合策略 - LOL；

## 如果是多次的囚徒困境问题呢？
也就是说两个罪犯多次面临这样同一个问题，且都可以**利用上一次对方处理该问题的动作**进行针对性的**改变**；

结论是，不管一个博弈重复多少次，只要它具有Nash均衡，那么其重复的结果同样就是Nash均衡进行对应次数的重复而已；

## 随机博弈
* 玩家：A1，A2
* 状态：s
* 动作：a for A1，b for A2
* 转换函数：T(s,(a,b),s')
* 奖励函数：R1(s,(a,b))，R2(s,(a,b))
* 折扣系数：gamma

## 对随机博弈进行条件设定限制后，它等价于其他的博弈
* R1=-R2:很明显，这样就构成了零和博弈；
* 只要只有一个玩家有影响，那么这就是MDP；
* |s|=1:只有一种状态，那么只能不停的重复这个博弈，因此是repeat game；

## 一般和博弈
wuwuwuwuwuwuwu
